{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab7315c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports + Download dataset directly (no manual download needed)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fde14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED 5572 messages successfully!\n",
      "\n",
      "First 5 rows:\n",
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Label distribution before mapping:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: PERFECTLY load your combined_data.csv (tested on your screenshot)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# This single line handles EVERYTHING for your file\n",
    "df = pd.read_csv(\n",
    "    \"combined_data.csv\",\n",
    "    encoding=\"latin-1\",          # required for this old dataset\n",
    "    usecols=[0, 1],              # take only column 0 (v1 = label) and column 1 (v2 = text)\n",
    "    names=['label', 'text'],     # rename them directly\n",
    "    header=0,                    # first row has headers v1,v2,v3,... so skip it\n",
    "    engine=\"python\"\n",
    ")\n",
    "\n",
    "# Quick clean-up\n",
    "df['text'] = df['text'].astype(str).str.strip()\n",
    "df = df[df['text'].str.len() > 0]\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "print(f\"LOADED {len(df)} messages successfully!\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nLabel distribution before mapping:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20ef457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected → Text column: 'text' | Label column: 'label'\n",
      "\n",
      "CLEANING DONE!\n",
      "Final dataset shape : (5572, 2)\n",
      "Spam  messages      : 747\n",
      "Ham   messages      : 4825\n",
      "\n",
      "First 5 rows:\n",
      "                                                text  label\n",
      "0  Go until jurong point, crazy.. Available only ...      0\n",
      "1                      Ok lar... Joking wif u oni...      0\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "3  U dun say so early hor... U c already then say...      0\n",
      "4  Nah I don't think he goes to usf, he lives aro...      0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Auto-detect columns and clean your combined_data.csv (FIXED)\n",
    "\n",
    "# Possible column names in different Kaggle spam datasets\n",
    "text_cols   = ['text', 'message', 'Message', 'v2', 'email', 'sms', 'Email Text', 'message_body']\n",
    "label_cols  = ['label', 'category', 'Category', 'v1', 'spam', 'type', 'Label']\n",
    "\n",
    "text_col  = None\n",
    "label_col = None\n",
    "\n",
    "for col in df.columns:\n",
    "    col_lower = col.strip().lower()\n",
    "    if any(name.lower() in col_lower for name in text_cols):\n",
    "        text_col = col\n",
    "    if any(name.lower() in col_lower for name in label_cols):\n",
    "        label_col = col\n",
    "\n",
    "if text_col is None or label_col is None:\n",
    "    print(\"Could not auto-detect columns!\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    print(\"Please rename them manually to 'text' and 'label'\")\n",
    "else:\n",
    "    print(f\"Detected → Text column: '{text_col}' | Label column: '{label_col}'\")\n",
    "    \n",
    "    # Rename to standard names\n",
    "    df = df.rename(columns={text_col: 'text', label_col: 'label'})\n",
    "    \n",
    "    # Keep only the two columns we need\n",
    "    df = df[['text', 'label']].copy()\n",
    "    \n",
    "    # Clean text\n",
    "    df['text'] = df['text'].astype(str).str.strip()\n",
    "    df = df[df['text'].str.len() > 0]          # remove empty rows\n",
    "    df = df.dropna(subset=['text'])           # safety\n",
    "    \n",
    "    # Clean and convert labels\n",
    "    df['label'] = df['label'].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # Fixed mapping (this was the syntax error!)\n",
    "    label_map = {\n",
    "        'spam': 1, 'ham': 0,\n",
    "        '1': 1, '0': 0,\n",
    "        'yes': 1, 'no': 0,\n",
    "        'true': 1, 'false': 0\n",
    "    }\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "    \n",
    "    # Anything that didn't map becomes NaN → drop those rows\n",
    "    df = df.dropna(subset=['label'])\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    \n",
    "    print(f\"\\nCLEANING DONE!\")\n",
    "    print(f\"Final dataset shape : {df.shape}\")\n",
    "    print(f\"Spam  messages      : {df['label'].sum()}\")\n",
    "    print(f\"Ham   messages      : {len(df) - df['label'].sum()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "feaa418c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Accuracy: 0.9605 (96.05%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.96      1.00      0.98       966\n",
      "        Spam       0.99      0.71      0.83       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.86      0.90      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train the model (takes ~10 seconds)\n",
    "\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Best pipeline for spam detection\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        max_features=50000,\n",
    "        ngram_range=(1, 2),\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('clf', LogisticRegression(max_iter=1000, C=1.0))\n",
    "])\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adb3d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'spam_classifier_model.pkl'\n",
      "\n",
      "Live Testing:\n",
      "→ 'Free entry in 2 a wkly comp to win FA Cup final tkts!'\n",
      "   NOT SPAM (63.1% confidence)\n",
      "\n",
      "→ 'Hey, are you free tonight for dinner?'\n",
      "   NOT SPAM (89.4% confidence)\n",
      "\n",
      "→ 'Congratulations! You've won $1000. Click here to claim'\n",
      "   SPAM (51.5% confidence)\n",
      "\n",
      "→ 'Can we reschedule the meeting to 3pm?'\n",
      "   NOT SPAM (94.3% confidence)\n",
      "\n",
      "→ 'URGENT: Your account has been compromised. Login now'\n",
      "   NOT SPAM (73.5% confidence)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Save model + Quick test\n",
    "\n",
    "joblib.dump(model, 'spam_classifier_model.pkl')\n",
    "print(\"Model saved as 'spam_classifier_model.pkl'\")\n",
    "\n",
    "# Test with real messages\n",
    "test_messages = [\n",
    "    \"Free entry in 2 a wkly comp to win FA Cup final tkts!\",\n",
    "    \"Hey, are you free tonight for dinner?\",\n",
    "    \"Congratulations! You've won $1000. Click here to claim\",\n",
    "    \"Can we reschedule the meeting to 3pm?\",\n",
    "    \"URGENT: Your account has been compromised. Login now\"\n",
    "]\n",
    "\n",
    "print(\"\\nLive Testing:\")\n",
    "for msg in test_messages:\n",
    "    pred = model.predict([msg])[0]\n",
    "    prob = model.predict_proba([msg])[0].max()\n",
    "    result = \"SPAM\" if pred == 1 else \"NOT SPAM\"\n",
    "    print(f\"→ '{msg}'\")\n",
    "    print(f\"   {result} ({prob:.1%} confidence)\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
